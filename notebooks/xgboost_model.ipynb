{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install & Import\n",
    "# !pip install xgboost \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"../data/processed/clean_telco_churn.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"Churn\"])\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737514fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Baseline XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]),\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4256d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_prob = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xgb_results = {\n",
    "    \"model_name\": \"XGBoost\",\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_prob),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "    \"f1_score\": f1_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "xgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results to JSON\n",
    "import json\n",
    "\n",
    "with open(\"../results/xgboost.json\", \"w\") as f:\n",
    "    json.dump(xgb_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Against Final Model\n",
    "files.append(\"../results/xgboost.json\")\n",
    "\n",
    "comparison_df = pd.DataFrame([\n",
    "    json.load(open(f)) for f in files\n",
    "])\n",
    "\n",
    "comparison_df.sort_values(by=\"recall\", ascending=False)\n",
    "\n",
    "\n",
    "# If XGBoost:\n",
    "# ‚ùå Improves recall by < 2% ‚Üí KEEP Random Forest\n",
    "# ‚úÖ Improves recall by ‚â• 2‚Äì3% ‚Üí XGBoost becomes final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3b58a",
   "metadata": {},
   "source": [
    "## üöÄ XGBoost Evaluation\n",
    "\n",
    "XGBoost was evaluated as an advanced model to determine whether boosting could improve churn detection.\n",
    "\n",
    "While XGBoost demonstrated strong performance, the improvement over the tuned Random Forest was marginal. Given the increased complexity and reduced interpretability, the tuned Random Forest remains the final selected model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
